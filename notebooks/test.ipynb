{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatedUpScalar(nn.Module):\n",
    "    def __init__(self, first_value, last_value, nb_steps, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_value = first_value\n",
    "        self.step = (max(first_value, last_value) - min(first_value, last_value)) / nb_steps\n",
    "\n",
    "        if first_value > last_value:\n",
    "            self._factor = -1\n",
    "        else:\n",
    "            self._factor = 1\n",
    "\n",
    "        self._increment = 0\n",
    "\n",
    "        print(\"Heated-up factor is {}.\".format(self.factor))\n",
    "\n",
    "    def on_task_end(self):\n",
    "        self._increment += 1\n",
    "        print(\"Heated-up factor is {}.\".format(self.factor))\n",
    "\n",
    "    @property\n",
    "    def factor(self):\n",
    "        return self.first_value + (self._factor * self._increment * self.step)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.factor * inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heated-up factor is 4.0.\n"
     ]
    }
   ],
   "source": [
    "h = HeatedUpScalar(4, 16, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heated-up factor is 6.0.\n",
      "Heated-up factor is 8.0.\n",
      "Heated-up factor is 10.0.\n",
      "Heated-up factor is 12.0.\n",
      "Heated-up factor is 14.0.\n",
      "Heated-up factor is 16.0.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(6):\n",
    "    h.on_task_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 10]), tensor(0.4027))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.mm(x[..., 0], x[..., 1].t())\n",
    "y.shape, y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[..., 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.2924), torch.Size([10]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor = x[..., 0]\n",
    "negative = x[..., 1]\n",
    "\n",
    "neg_dis = torch.sum(torch.mul(anchor,negative),1)\n",
    "dim = anchor.size(1)\n",
    "gor = torch.pow(torch.mean(neg_dis),2) + torch.clamp(torch.mean(torch.pow(neg_dis,2))-1.0/dim, min=0.0)\n",
    "\n",
    "gor, neg_dis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2049)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(\n",
    "    x[0, 0],\n",
    "    x[0, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2049]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(\n",
    "    x[0, 0].view(1, -1),\n",
    "    x[0, 1].view(-1,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4.]), tensor([0.1826, 0.3651, 0.5477, 0.7303]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4).float() + 1\n",
    "x, F.normalize(x,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 2, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy_per_class = 2\n",
    "nb_class = 4\n",
    "nb_samples = 5\n",
    "\n",
    "x = F.normalize(torch.randn(nb_samples, 10), dim=1, p=2)\n",
    "y = F.normalize(torch.randn(nb_class * proxy_per_class, 10), dim=1, p=2)\n",
    "\n",
    "targets = torch.randint(nb_class, size=(5,))\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi = torch.mm(x, y.t())\n",
    "simi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_nca(similarities, targets, proxy_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2707, 1.9096, 2.1086, 1.5890])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerator = torch.exp(torch.diagonal(simi.transpose(0, 1)[targets]))\n",
    "mask = torch.ones(simi.shape[0], simi.shape[1])\n",
    "mask[torch.arange(simi.shape[0]), targets] = 0\n",
    "\n",
    "denominator = torch.exp(simi) * mask\n",
    "\n",
    "-torch.log(numerator / denominator.sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities= torch.randn((5,3)).to(\"cuda:0\")\n",
    "targets = torch.tensor([0, 0, 1, 1, 2]).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(similarities, targets, s=30, m=0.4):\n",
    "    numerator = s * (torch.diagonal(similarities.transpose(0, 1)[targets]) - m)\n",
    "    denominator_but_right = torch.cat(\n",
    "        [\n",
    "            torch.cat((similarities[i, :y], similarities[i, y + 1:])).unsqueeze(0)\n",
    "            for i, y in enumerate(targets)\n",
    "        ],\n",
    "        dim=0\n",
    "    )\n",
    "    denominator = torch.exp(numerator) + torch.sum(torch.exp(s * denominator_but_right), dim=1)\n",
    "    loss = numerator - torch.log(denominator)\n",
    "    return -torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.8319, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo(similarities, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12 ms ± 114 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit foo(similarities, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baz(similarities, targets, s=30, m=0.4):    \n",
    "    numerator = s * (torch.diagonal(similarities.transpose(0, 1)[targets]) - m)\n",
    "    \n",
    "    all_deno = torch.exp(s * similarities)\n",
    "    all_deno[torch.arange(all_deno.shape[0]), targets] *= 0\n",
    "        \n",
    "    denominator = torch.exp(numerator) + torch.sum(all_deno, dim=1)\n",
    "    loss = numerator - torch.log(denominator)\n",
    "    return -torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.8319, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baz(similarities, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506 µs ± 76.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit baz(similarities, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar(similarities, targets, s=30, m=0.4):    \n",
    "    numerator = s * (torch.diagonal(similarities.transpose(0, 1)[targets]) - m)\n",
    "    \n",
    "    all_deno = torch.exp(s * similarities)\n",
    "    mask = torch.ones(all_deno.shape[0], all_deno.shape[1]).to(all_deno.device)\n",
    "    mask[torch.arange(all_deno.shape[0]), targets] = 0\n",
    "    \n",
    "    all_deno = all_deno * mask\n",
    "        \n",
    "    denominator = torch.exp(numerator) + torch.sum(all_deno, dim=1)\n",
    "    loss = numerator - torch.log(denominator)\n",
    "    return -torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.8319, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar(similarities, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430 µs ± 42.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bar(similarities, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3718, 1.4330],\n",
       "        [0.0000, 0.7630, 3.7366],\n",
       "        [0.3122, 0.0000, 0.5891],\n",
       "        [2.0226, 0.0000, 1.7250],\n",
       "        [0.6983, 0.4463, 0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_deno = torch.exp(1 * similarities)\n",
    "for row_idx in range(similarities.shape[0]):\n",
    "    all_deno[row_idx, targets[row_idx]] *= 0.\n",
    "all_deno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3718, 1.4330],\n",
       "        [0.0000, 0.7630, 3.7366],\n",
       "        [0.3122, 0.0000, 0.5891],\n",
       "        [2.0226, 0.0000, 1.7250],\n",
       "        [0.6983, 0.4463, 0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_deno = torch.exp(1 * similarities)\n",
    "all_deno[torch.arange(all_deno.shape[0]), targets] *= 0\n",
    "all_deno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3182,  1.3182, -1.1642, -1.1642, -0.8996], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.view(-1)[targets.shape[0] + targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5933, -0.9895,  0.3597,  2.2619, -0.2704,  1.3182, -1.1642, -0.8996,\n",
       "        -0.5291,  0.7044,  1.2560,  0.5452, -0.3590, -0.8067, -0.8009],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5933, -0.9895,  0.3597],\n",
       "        [ 2.2619, -0.2704,  1.3182],\n",
       "        [-1.1642, -0.8996, -0.5291],\n",
       "        [ 0.7044,  1.2560,  0.5452],\n",
       "        [-0.3590, -0.8067, -0.8009]], device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_deno = torch.exp(similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mer_non_vectorized(x, y):\n",
    "    loss = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            loss += (x[i][j] - y[i][j]) * torch.log(x[i][j])\n",
    "            \n",
    "    return loss / x.shape[0]\n",
    "\n",
    "mer_non_vectorized(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5632)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mer_vectorized(x, y):\n",
    "    return torch.mean(((x - y) * torch.log(x)).sum(-1), dim=0)\n",
    "    \n",
    "mer_vectorized(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1, 2, 0],\n",
    "    [0, 2, 3],\n",
    "    [1, 1, 0],\n",
    "    [5, 8, 3]\n",
    "]).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1623, 1.0000, 7.8102, 3.3166, 7.8102, 8.6023])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pdist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.addmm_(1, -2, inputs, inputs.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.,  -4.,  -3., -21.],\n",
       "        [ -4., -13.,  -2., -25.],\n",
       "        [ -3.,  -2.,  -2., -13.],\n",
       "        [-21., -25., -13., -98.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x, -x.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 10)\n",
    "y = torch.randn(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6034)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(torch.pdist(x) - torch.pdist(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 10, 7, 7)\n",
    "y = torch.randn(3, 10, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(x).sum(dim=1).view(x.shape[0], -1)\n",
    "y = F.relu(y).sum(dim=1).view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9623)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.frobenius_norm(F.normalize(x, dim=1)- F.normalize(y, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9623)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.frobenius_norm(F.normalize(y, dim=1)- F.normalize(x, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 1, 2],\n",
       "        [1, 2, 0, 3],\n",
       "        [2, 1, 3, 0],\n",
       "        [3, 0, 2, 1]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = F.normalize(x, dim=1, p=2)\n",
    "simi = 2 * (1 - torch.mm(xx, xx.transpose(1, 0)) + 1e-8)\n",
    "\n",
    "simi.argsort(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 1, 2],\n",
       "        [2, 0, 3],\n",
       "        [1, 3, 0],\n",
       "        [0, 2, 1]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = simi.argsort(dim=1)[..., 1:]\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, 11.8433, 27.0889,  9.4486],\n",
       "        [11.8433,  1.0000,  2.6142, 22.4042],\n",
       "        [27.0889,  2.6142,  1.0000, 14.4634],\n",
       "        [ 9.4486, 22.4042, 14.4634,  1.0000]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi_exp = torch.exp(simi)\n",
    "simi_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(t.shape[0], t.shape[0])\n",
    "for row_index in range(t.shape[0]):\n",
    "    col_indexes = (t == t[row_index])\n",
    "    y[row_index, col_indexes] = 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.eye(t.shape[0]).byte()\n",
    "y_nodiag = y[~mask].byte()\n",
    "simi_nodiag = simi_exp[~mask]\n",
    "\n",
    "y_nodiag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_simi = simi_nodiag[y_nodiag].sum()\n",
    "n_simi = simi_nodiag[~y_nodiag].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_simi = torch.log(p_simi)\n",
    "log_pn_simi = torch.log(p_simi + n_simi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = log_pn_simi - log_p_simi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5739)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mat = t.view(t.shape[0], 1)\n",
    "t_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mat2 = (t_mat == t_mat.t()).float()\n",
    "t_mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.0000, 0.5000, 0.0000],\n",
       "        [0.0000, 0.5000, 0.0000, 0.5000],\n",
       "        [0.5000, 0.0000, 0.5000, 0.0000],\n",
       "        [0.0000, 0.5000, 0.0000, 0.5000]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mat3 = t_mat2 / t_mat2.sum(dim=-1)\n",
    "t_mat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7768)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(F.softmax(simi, dim=-1), t_mat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.5000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.5000],\n",
       "        [0.5000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5000, 0.0000]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mat3[~mask].view(mask.shape[0], mask.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1842e-07,  2.4718e+00,  3.2991e+00,  2.2459e+00],\n",
       "        [ 2.4718e+00, -4.5684e-07,  9.6095e-01,  3.1092e+00],\n",
       "        [ 3.2991e+00,  9.6095e-01,  2.0000e-08,  2.6716e+00],\n",
       "        [ 2.2459e+00,  3.1092e+00,  2.6716e+00, -2.1842e-07]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2448, 0.5599, 0.1953],\n",
       "        [0.3213, 0.0709, 0.6078],\n",
       "        [0.6133, 0.0592, 0.3275],\n",
       "        [0.2040, 0.4837, 0.3123]])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = simi[~mask].view(mask.shape[0], mask.shape[0]-1)\n",
    "F.softmax(tmp, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1886.7542])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul((simi[mask] + simi_nodiag[y_nodiag]).view(-1, 1).repeat(2, 1).t(), simi_nodiag[~y_nodiag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi_nodiag[~y_nodiag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(simi[mask] + simi_nodiag[y_nodiag]).view(-1, 1).repeat(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa = torch.randn(1, 10)\n",
    "xp = torch.randn(1, 10)\n",
    "xn = torch.randn(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.7054)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm((xa + xp), xn.t())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-311-99a05660d162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiag_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pos_no_diago\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_set_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pos_no_diago\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pos_no_diago\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "        diag_false = tf.constant(np.array([0.0 for _ in range(self._batch_size)], dtype=\"float32\"))\n",
    "        y_pos_no_diago = tf.matrix_set_diag(y_true, diag_false)\n",
    "\n",
    "        y_pos_no_diago = K.cast(y_pos_no_diago, tf.bool)\n",
    "        y_pos = K.cast(y_true, tf.bool)\n",
    "\n",
    "        p_similarity = tf.boolean_mask(y_pred, y_pos_no_diago)\n",
    "        p_similarity = K.reshape(p_similarity, (self._batch_size, self._images_per_label - 1))\n",
    "\n",
    "        n_similarity = tf.boolean_mask(y_pred, ~y_pos)\n",
    "        n_similarity = K.reshape(\n",
    "            n_similarity, (self._batch_size, self._batch_size - self._images_per_label)\n",
    "        )\n",
    "\n",
    "        sum_exp_p_similarity = K.sum(tf.exp(p_similarity), axis=1)\n",
    "        sum_exp_n_similarity = K.sum(tf.exp(n_similarity), axis=1)\n",
    "        log_sum_exp_p_similarity = K.log(sum_exp_p_similarity)\n",
    "        log_sum_exp_pn_similarity = K.log(sum_exp_p_similarity + sum_exp_n_similarity)\n",
    "        loss = log_sum_exp_pn_similarity - log_sum_exp_p_similarity\n",
    "        loss = K.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x, x.t()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x.t(), x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., 5., 5., 5., 5., 5.])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(8) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
