{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "import inclearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed 1\n"
     ]
    }
   ],
   "source": [
    "inclearn.train._set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.cifar.CIFAR100(\"data\", download=True, train=True, transform=train_transforms)\n",
    "test_dataset= datasets.cifar.CIFAR100(\"data\", download=True, train=False, transform=test_transforms)\n",
    "\n",
    "special_order = [  # Taken from original iCaRL implementation:\n",
    "        87, 0, 52, 58, 44, 91, 68, 97, 51, 15, 94, 92, 10, 72, 49, 78, 61, 14, 8, 86, 84, 96, 18,\n",
    "        24, 32, 45, 88, 11, 4, 67, 69, 66, 77, 47, 79, 93, 29, 50, 57, 83, 17, 81, 41, 12, 37, 59,\n",
    "        25, 20, 80, 73, 1, 28, 6, 46, 62, 82, 53, 9, 31, 75, 38, 63, 33, 74, 27, 22, 36, 3, 16, 21,\n",
    "        60, 19, 70, 90, 89, 43, 5, 42, 65, 76, 40, 30, 23, 85, 2, 95, 56, 48, 71, 64, 98, 13, 99, 7,\n",
    "        34, 55, 54, 26, 35, 39\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, num_workers=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(model, loader):\n",
    "    predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for inputs, targets in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        all_targets.append(targets.numpy())\n",
    "        \n",
    "        logits = model(inputs)\n",
    "        predictions.append(logits.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    \n",
    "    total_acc = (predictions == all_targets).sum() / len(all_targets)\n",
    "    \n",
    "    return all_targets, predictions, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = inclearn.lib.network.BasicNet(\"rebuffi\", device=device, use_bias=True)\n",
    "#model.add_classes(100)\n",
    "\n",
    "model = torchvision.models.resnet34(num_classes=100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [60, 120, 160], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/200, train_loss: 4.057, train_acc: 0.13, test_acc: 0.14\n",
      "Best acc! Saving model\n",
      "Epoch 1/200, train_loss: 3.486, train_acc: 0.2, test_acc: 0.21\n",
      "Best acc! Saving model\n",
      "Epoch 2/200, train_loss: 3.2, train_acc: 0.24, test_acc: 0.25\n",
      "Best acc! Saving model\n",
      "Epoch 3/200, train_loss: 2.996, train_acc: 0.27, test_acc: 0.28\n",
      "Best acc! Saving model\n",
      "Epoch 4/200, train_loss: 2.823, train_acc: 0.31, test_acc: 0.31\n",
      "Best acc! Saving model\n",
      "Epoch 5/200, train_loss: 2.672, train_acc: 0.33, test_acc: 0.33\n",
      "Best acc! Saving model\n",
      "Epoch 6/200, train_loss: 2.55, train_acc: 0.35, test_acc: 0.34\n",
      "Best acc! Saving model\n",
      "Epoch 7/200, train_loss: 2.446, train_acc: 0.36, test_acc: 0.34\n",
      "Best acc! Saving model\n",
      "Epoch 8/200, train_loss: 2.353, train_acc: 0.41, test_acc: 0.38\n",
      "Best acc! Saving model\n",
      "Epoch 9/200, train_loss: 2.266, train_acc: 0.42, test_acc: 0.39\n",
      "Best acc! Saving model\n",
      "Epoch 10/200, train_loss: 2.191, train_acc: 0.42, test_acc: 0.4\n",
      "Best acc! Saving model\n",
      "Epoch 11/200, train_loss: 2.12, train_acc: 0.45, test_acc: 0.41\n",
      "Best acc! Saving model\n",
      "Epoch 12/200, train_loss: 2.045, train_acc: 0.47, test_acc: 0.44\n",
      "Best acc! Saving model\n",
      "Epoch 13/200, train_loss: 1.987, train_acc: 0.48, test_acc: 0.42\n",
      "Epoch 14/200, train_loss: 1.92, train_acc: 0.49, test_acc: 0.43\n",
      "Epoch 15/200, train_loss: 1.867, train_acc: 0.51, test_acc: 0.45\n",
      "Best acc! Saving model\n",
      "Epoch 16/200, train_loss: 1.805, train_acc: 0.5, test_acc: 0.43\n",
      "Epoch 17/200, train_loss: 1.753, train_acc: 0.53, test_acc: 0.46\n",
      "Best acc! Saving model\n",
      "Epoch 18/200, train_loss: 1.707, train_acc: 0.55, test_acc: 0.46\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "\n",
    "best_model = None\n",
    "best_acc = -1.\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    _, _, train_acc = acc(model, train_loader)\n",
    "    _, _, test_acc = acc(model, test_loader)\n",
    "        \n",
    "    print(\"Epoch {}/{}, train_loss: {}, train_acc: {}, test_acc: {}\".format(\n",
    "        epoch, n_epochs,\n",
    "        round(epoch_loss / len(train_loader), 3),\n",
    "        round(train_acc, 2), round(test_acc, 2)\n",
    "    ))\n",
    "    \n",
    "    if test_acc > best_acc:\n",
    "        print(\"Best acc! Saving model\")\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_acc = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
